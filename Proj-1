import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
import folium
from datetime import datetime

class CreditCardFraudAnalysis:
    def __init__(self, data_path):
        """Initialize the analysis with the data file path."""
        self.data_path = data_path
        self.data = None
        
    def load_data(self):
        """Load and perform initial data preprocessing."""
        try:
            self.data = pd.read_csv(self.data_path)
            print("Data loaded successfully. Shape:", self.data.shape)
            return self.data.head()
        except Exception as e:
            print(f"Error loading data: {e}")
            return None

    def explore_fraud_patterns(self):
        """Analyze fraud patterns by product category and transaction amount."""
        if self.data is None:
            return "Please load data first."
        
        # Analysis by product category
        fraud_by_category = self.data.groupby('product_category')['is_fraud'].agg(['count', 'mean'])
        fraud_by_category = fraud_by_category.sort_values('mean', ascending=False)
        
        # Visualization
        plt.figure(figsize=(12, 6))
        sns.barplot(data=fraud_by_category.reset_index(), 
                   x='product_category', y='mean',
                   order=fraud_by_category.index)
        plt.xticks(rotation=45)
        plt.title('Fraud Rate by Product Category')
        plt.tight_layout()
        plt.show()
        
        # Analysis by transaction amount
        plt.figure(figsize=(10, 6))
        sns.boxplot(x='is_fraud', y='transaction_amount', data=self.data)
        plt.title('Transaction Amounts by Fraud Status')
        plt.show()
        
        return fraud_by_category

    def create_geospatial_visualization(self):
        """Create a map showing fraud rates by state."""
        if self.data is None:
            return "Please load data first."
            
        # Calculate fraud rates by state
        state_fraud_rates = self.data.groupby('state')['is_fraud'].agg(['count', 'mean'])
        
        # Create base map centered on US
        m = folium.Map(location=[37.0902, -95.7129], zoom_start=4)
        
        # Add choropleth layer
        folium.Choropleth(
            geo_data='us-states.json',  # You'll need this GeoJSON file
            name='choropleth',
            data=state_fraud_rates,
            columns=['state', 'mean'],
            key_on='feature.properties.name',
            fill_color='YlOrRd',
            fill_opacity=0.7,
            line_opacity=0.2,
            legend_name='Fraud Rate (%)'
        ).add_to(m)
        
        return m

    def analyze_age_correlation(self):
        """Analyze the relationship between customer age and fraud likelihood."""
        if self.data is None:
            return "Please load data first."
            
        # Create age groups
        self.data['age_group'] = pd.cut(self.data['customer_age'], 
                                      bins=[0, 25, 35, 45, 55, 65, 100],
                                      labels=['18-25', '26-35', '36-45', '46-55', '56-65', '65+'])
        
        # Calculate fraud rates by age group
        age_fraud_rates = self.data.groupby('age_group')['is_fraud'].agg(['count', 'mean'])
        
        # Visualization
        plt.figure(figsize=(10, 6))
        sns.barplot(data=age_fraud_rates.reset_index(), 
                   x='age_group', y='mean')
        plt.title('Fraud Rate by Age Group')
        plt.ylabel('Fraud Rate')
        plt.xlabel('Age Group')
        plt.show()
        
        # Statistical test (Chi-square test of independence)
        from scipy.stats import chi2_contingency
        contingency_table = pd.crosstab(self.data['age_group'], self.data['is_fraud'])
        chi2, p_value, dof, expected = chi2_contingency(contingency_table)
        
        return {
            'age_fraud_rates': age_fraud_rates,
            'chi_square_test': {
                'chi2_statistic': chi2,
                'p_value': p_value
            }
        }

    def build_fraud_detection_model(self):
        """Build and evaluate a fraud detection model."""
        if self.data is None:
            return "Please load data first."
            
        # Prepare features and target
        features = ['transaction_amount', 'customer_age', 'product_category']
        X = pd.get_dummies(self.data[features], columns=['product_category'])
        y = self.data['is_fraud']
        
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # Scale features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Train model (using Random Forest as an example)
        from sklearn.ensemble import RandomForestClassifier
        model = RandomForestClassifier(class_weight='balanced', random_state=42)
        model.fit(X_train_scaled, y_train)
        
        # Make predictions
        y_pred = model.predict(X_test_scaled)
        
        # Evaluate model
        print("\nClassification Report:")
        print(classification_report(y_test, y_pred))
        
        # Plot confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d',
                   xticklabels=['Not Fraud', 'Fraud'],
                   yticklabels=['Not Fraud', 'Fraud'])
        plt.title('Confusion Matrix')
        plt.show()
        
        return model

if __name__ == "__main__":
    # Initialize analyzer with absolute path
    import os
    data_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'credit_card_data.csv')
    analyzer = CreditCardFraudAnalysis(data_path)
    
    # Load data
    print("Loading data...")
    analyzer.load_data()
    
    # Perform analysis
    print("\nAnalyzing fraud patterns...")
    fraud_patterns = analyzer.explore_fraud_patterns()
    print("\nFraud rates by category:")
    print(fraud_patterns)
    
    print("\nSkipping geospatial visualization (requires GeoJSON file)")
    # map_viz = analyzer.create_geospatial_visualization()
    # map_viz.save('fraud_map.html')
    
    print("\nAnalyzing age correlation...")

    age_analysis = analyzer.analyze_age_correlation()
    print("Age analysis results:", age_analysis)
    
    print("\nBuilding fraud detection model...")
    model = analyzer.build_fraud_detection_model()


/* Data Loading: Successfully loaded 15 sample transactions

Fraud Patterns:

Jewelry has the highest fraud rate (100%)
Electronics follows with 60% fraud rate
Furniture shows 50% fraud rate
Clothing, Food, and Groceries show no fraud in our sample
Age Correlation:

Age groups show varying fraud rates:
65+ shows 100% fraud rate (though small sample size)
36-45 shows 75% fraud rate
56-65 shows 50% fraud rate
26-35 shows 20% fraud rate
Other age groups show 0% fraud rate
The chi-square test p-value (0.264) suggests the relationship between age and fraud is not statistically significant at the conventional 0.05 level
Model Performance:

The model shows perfect performance on the test set
However, this is likely due to the small sample size (15 records)
In a real-world scenario with more data, we would expect more varied performance metrics */
